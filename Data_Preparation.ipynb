{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "Data_Preparation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "wN0G9BST02ru"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/casperbh96/mbml/blob/master/Data_Preparation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3mke2L002rc",
        "colab_type": "text"
      },
      "source": [
        "# Importing the packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4n8C_LBViwNl",
        "colab_type": "code",
        "outputId": "3ef6f937-a9b6-486c-8aac-3f86ba12540c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# Install Pyro, if necessary\n",
        "!pip install pyro-ppl"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyro-ppl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/77/4db4946f6b5bf0601869c7b7594def42a7197729167484e1779fff5ca0d6/pyro_ppl-1.3.1-py3-none-any.whl (520kB)\n",
            "\r\u001b[K     |▋                               | 10kB 19.0MB/s eta 0:00:01\r\u001b[K     |█▎                              | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |█▉                              | 30kB 2.1MB/s eta 0:00:01\r\u001b[K     |██▌                             | 40kB 2.4MB/s eta 0:00:01\r\u001b[K     |███▏                            | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |███▊                            | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |████▍                           | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 92kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 337kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 348kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 358kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 368kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 378kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 389kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 399kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 409kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 419kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 430kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 440kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 450kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 460kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 471kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 481kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 491kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 501kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 512kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 522kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (1.5.0+cu101)\n",
            "Collecting pyro-api>=0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fc/81/957ae78e6398460a7230b0eb9b8f1cb954c5e913e868e48d89324c68cec7/pyro_api-0.1.2-py3-none-any.whl\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (1.18.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (3.2.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->pyro-ppl) (0.16.0)\n",
            "Installing collected packages: pyro-api, pyro-ppl\n",
            "Successfully installed pyro-api-0.1.2 pyro-ppl-1.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFLJgVvW02re",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "974d3f6e-846a-4e0a-d94f-bda9fd7d2fcd"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn import linear_model\n",
        "import copy\n",
        "import torch\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "import pyro\n",
        "import pyro.distributions as dist\n",
        "from pyro.contrib.autoguide import AutoDiagonalNormal, AutoMultivariateNormal\n",
        "from pyro.infer import MCMC, NUTS, HMC, SVI, Trace_ELBO\n",
        "from pyro.optim import Adam, ClippedAdam\n",
        "\n",
        "pd.set_option('display.max_columns', 50)\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCqtx0jR02rk",
        "colab_type": "text"
      },
      "source": [
        "# Loading the dataset\n",
        "\n",
        "This is the Santander Product Recommendation dataset from [Kaggle](https://www.kaggle.com/c/santander-product-recommendation/data)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BI_eUa3Q1qiK",
        "colab_type": "code",
        "outputId": "9c672cef-471a-4487-a21c-e5b38186f2bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQjPQIs002rl",
        "colab_type": "code",
        "outputId": "95823f7e-88d2-4560-ff34-da50987d41ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "#train_path = 'data/train_ver2.csv'\n",
        "train_path = '/content/gdrive/My Drive/MSc: AI/2. semester/MBML/train_ver2.csv'\n",
        "#train_path = '/content/gdrive/My Drive/DTU/Model-based machined learning/project/data/train_ver2.csv'\n",
        "\n",
        "train_df = pd.read_csv(train_path, parse_dates=['fecha_dato', 'fecha_alta', 'ult_fec_cli_1t'], sep=\",\",na_values = ['?', 'NA'])\n",
        "\n",
        "train_df.head(5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (5,8,11,15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fecha_dato</th>\n",
              "      <th>ncodpers</th>\n",
              "      <th>ind_empleado</th>\n",
              "      <th>pais_residencia</th>\n",
              "      <th>sexo</th>\n",
              "      <th>age</th>\n",
              "      <th>fecha_alta</th>\n",
              "      <th>ind_nuevo</th>\n",
              "      <th>antiguedad</th>\n",
              "      <th>indrel</th>\n",
              "      <th>ult_fec_cli_1t</th>\n",
              "      <th>indrel_1mes</th>\n",
              "      <th>tiprel_1mes</th>\n",
              "      <th>indresi</th>\n",
              "      <th>indext</th>\n",
              "      <th>conyuemp</th>\n",
              "      <th>canal_entrada</th>\n",
              "      <th>indfall</th>\n",
              "      <th>tipodom</th>\n",
              "      <th>cod_prov</th>\n",
              "      <th>nomprov</th>\n",
              "      <th>ind_actividad_cliente</th>\n",
              "      <th>renta</th>\n",
              "      <th>segmento</th>\n",
              "      <th>ind_ahor_fin_ult1</th>\n",
              "      <th>ind_aval_fin_ult1</th>\n",
              "      <th>ind_cco_fin_ult1</th>\n",
              "      <th>ind_cder_fin_ult1</th>\n",
              "      <th>ind_cno_fin_ult1</th>\n",
              "      <th>ind_ctju_fin_ult1</th>\n",
              "      <th>ind_ctma_fin_ult1</th>\n",
              "      <th>ind_ctop_fin_ult1</th>\n",
              "      <th>ind_ctpp_fin_ult1</th>\n",
              "      <th>ind_deco_fin_ult1</th>\n",
              "      <th>ind_deme_fin_ult1</th>\n",
              "      <th>ind_dela_fin_ult1</th>\n",
              "      <th>ind_ecue_fin_ult1</th>\n",
              "      <th>ind_fond_fin_ult1</th>\n",
              "      <th>ind_hip_fin_ult1</th>\n",
              "      <th>ind_plan_fin_ult1</th>\n",
              "      <th>ind_pres_fin_ult1</th>\n",
              "      <th>ind_reca_fin_ult1</th>\n",
              "      <th>ind_tjcr_fin_ult1</th>\n",
              "      <th>ind_valo_fin_ult1</th>\n",
              "      <th>ind_viv_fin_ult1</th>\n",
              "      <th>ind_nomina_ult1</th>\n",
              "      <th>ind_nom_pens_ult1</th>\n",
              "      <th>ind_recibo_ult1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015-01-28</td>\n",
              "      <td>1375586</td>\n",
              "      <td>N</td>\n",
              "      <td>ES</td>\n",
              "      <td>H</td>\n",
              "      <td>35</td>\n",
              "      <td>2015-01-12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaT</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>S</td>\n",
              "      <td>N</td>\n",
              "      <td>NaN</td>\n",
              "      <td>KHL</td>\n",
              "      <td>N</td>\n",
              "      <td>1.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>MALAGA</td>\n",
              "      <td>1.0</td>\n",
              "      <td>87218.10</td>\n",
              "      <td>02 - PARTICULARES</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015-01-28</td>\n",
              "      <td>1050611</td>\n",
              "      <td>N</td>\n",
              "      <td>ES</td>\n",
              "      <td>V</td>\n",
              "      <td>23</td>\n",
              "      <td>2012-08-10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>35</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaT</td>\n",
              "      <td>1</td>\n",
              "      <td>I</td>\n",
              "      <td>S</td>\n",
              "      <td>S</td>\n",
              "      <td>NaN</td>\n",
              "      <td>KHE</td>\n",
              "      <td>N</td>\n",
              "      <td>1.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>CIUDAD REAL</td>\n",
              "      <td>0.0</td>\n",
              "      <td>35548.74</td>\n",
              "      <td>03 - UNIVERSITARIO</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015-01-28</td>\n",
              "      <td>1050612</td>\n",
              "      <td>N</td>\n",
              "      <td>ES</td>\n",
              "      <td>V</td>\n",
              "      <td>23</td>\n",
              "      <td>2012-08-10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>35</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaT</td>\n",
              "      <td>1</td>\n",
              "      <td>I</td>\n",
              "      <td>S</td>\n",
              "      <td>N</td>\n",
              "      <td>NaN</td>\n",
              "      <td>KHE</td>\n",
              "      <td>N</td>\n",
              "      <td>1.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>CIUDAD REAL</td>\n",
              "      <td>0.0</td>\n",
              "      <td>122179.11</td>\n",
              "      <td>03 - UNIVERSITARIO</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015-01-28</td>\n",
              "      <td>1050613</td>\n",
              "      <td>N</td>\n",
              "      <td>ES</td>\n",
              "      <td>H</td>\n",
              "      <td>22</td>\n",
              "      <td>2012-08-10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>35</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaT</td>\n",
              "      <td>1</td>\n",
              "      <td>I</td>\n",
              "      <td>S</td>\n",
              "      <td>N</td>\n",
              "      <td>NaN</td>\n",
              "      <td>KHD</td>\n",
              "      <td>N</td>\n",
              "      <td>1.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>ZARAGOZA</td>\n",
              "      <td>0.0</td>\n",
              "      <td>119775.54</td>\n",
              "      <td>03 - UNIVERSITARIO</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015-01-28</td>\n",
              "      <td>1050614</td>\n",
              "      <td>N</td>\n",
              "      <td>ES</td>\n",
              "      <td>V</td>\n",
              "      <td>23</td>\n",
              "      <td>2012-08-10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>35</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaT</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>S</td>\n",
              "      <td>N</td>\n",
              "      <td>NaN</td>\n",
              "      <td>KHE</td>\n",
              "      <td>N</td>\n",
              "      <td>1.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>ZARAGOZA</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>03 - UNIVERSITARIO</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  fecha_dato  ncodpers ind_empleado pais_residencia sexo  age fecha_alta  \\\n",
              "0 2015-01-28   1375586            N              ES    H   35 2015-01-12   \n",
              "1 2015-01-28   1050611            N              ES    V   23 2012-08-10   \n",
              "2 2015-01-28   1050612            N              ES    V   23 2012-08-10   \n",
              "3 2015-01-28   1050613            N              ES    H   22 2012-08-10   \n",
              "4 2015-01-28   1050614            N              ES    V   23 2012-08-10   \n",
              "\n",
              "   ind_nuevo antiguedad  indrel ult_fec_cli_1t indrel_1mes tiprel_1mes  \\\n",
              "0        0.0          6     1.0            NaT           1           A   \n",
              "1        0.0         35     1.0            NaT           1           I   \n",
              "2        0.0         35     1.0            NaT           1           I   \n",
              "3        0.0         35     1.0            NaT           1           I   \n",
              "4        0.0         35     1.0            NaT           1           A   \n",
              "\n",
              "  indresi indext conyuemp canal_entrada indfall  tipodom  cod_prov  \\\n",
              "0       S      N      NaN           KHL       N      1.0      29.0   \n",
              "1       S      S      NaN           KHE       N      1.0      13.0   \n",
              "2       S      N      NaN           KHE       N      1.0      13.0   \n",
              "3       S      N      NaN           KHD       N      1.0      50.0   \n",
              "4       S      N      NaN           KHE       N      1.0      50.0   \n",
              "\n",
              "       nomprov  ind_actividad_cliente      renta            segmento  \\\n",
              "0       MALAGA                    1.0   87218.10   02 - PARTICULARES   \n",
              "1  CIUDAD REAL                    0.0   35548.74  03 - UNIVERSITARIO   \n",
              "2  CIUDAD REAL                    0.0  122179.11  03 - UNIVERSITARIO   \n",
              "3     ZARAGOZA                    0.0  119775.54  03 - UNIVERSITARIO   \n",
              "4     ZARAGOZA                    1.0        NaN  03 - UNIVERSITARIO   \n",
              "\n",
              "   ind_ahor_fin_ult1  ind_aval_fin_ult1  ind_cco_fin_ult1  ind_cder_fin_ult1  \\\n",
              "0                  0                  0                 1                  0   \n",
              "1                  0                  0                 1                  0   \n",
              "2                  0                  0                 1                  0   \n",
              "3                  0                  0                 0                  0   \n",
              "4                  0                  0                 1                  0   \n",
              "\n",
              "   ind_cno_fin_ult1  ind_ctju_fin_ult1  ind_ctma_fin_ult1  ind_ctop_fin_ult1  \\\n",
              "0                 0                  0                  0                  0   \n",
              "1                 0                  0                  0                  0   \n",
              "2                 0                  0                  0                  0   \n",
              "3                 0                  0                  0                  0   \n",
              "4                 0                  0                  0                  0   \n",
              "\n",
              "   ind_ctpp_fin_ult1  ind_deco_fin_ult1  ind_deme_fin_ult1  ind_dela_fin_ult1  \\\n",
              "0                  0                  0                  0                  0   \n",
              "1                  0                  0                  0                  0   \n",
              "2                  0                  0                  0                  0   \n",
              "3                  0                  1                  0                  0   \n",
              "4                  0                  0                  0                  0   \n",
              "\n",
              "   ind_ecue_fin_ult1  ind_fond_fin_ult1  ind_hip_fin_ult1  ind_plan_fin_ult1  \\\n",
              "0                  0                  0                 0                  0   \n",
              "1                  0                  0                 0                  0   \n",
              "2                  0                  0                 0                  0   \n",
              "3                  0                  0                 0                  0   \n",
              "4                  0                  0                 0                  0   \n",
              "\n",
              "   ind_pres_fin_ult1  ind_reca_fin_ult1  ind_tjcr_fin_ult1  ind_valo_fin_ult1  \\\n",
              "0                  0                  0                  0                  0   \n",
              "1                  0                  0                  0                  0   \n",
              "2                  0                  0                  0                  0   \n",
              "3                  0                  0                  0                  0   \n",
              "4                  0                  0                  0                  0   \n",
              "\n",
              "   ind_viv_fin_ult1  ind_nomina_ult1  ind_nom_pens_ult1  ind_recibo_ult1  \n",
              "0                 0              0.0                0.0                0  \n",
              "1                 0              0.0                0.0                0  \n",
              "2                 0              0.0                0.0                0  \n",
              "3                 0              0.0                0.0                0  \n",
              "4                 0              0.0                0.0                0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VLoKLls02rp",
        "colab_type": "code",
        "outputId": "c378401e-398a-40ec-8a8e-a89c8b463806",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "#test_path = 'data/test_ver2.csv'\n",
        "test_path = '/content/gdrive/My Drive/MSc: AI/2. semester/MBML/test_ver2.csv'\n",
        "#test_path = '/content/gdrive/My Drive/DTU/Model-based machined learning/project/data/test_ver2.csv'\n",
        "\n",
        "test_df = pd.read_csv(test_path, parse_dates=['fecha_dato', 'fecha_alta', 'ult_fec_cli_1t'],\n",
        "                      sep=\",\",na_values = ['?', 'NA'], nrows = 50000)\n",
        "\n",
        "test_df.head(5)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fecha_dato</th>\n",
              "      <th>ncodpers</th>\n",
              "      <th>ind_empleado</th>\n",
              "      <th>pais_residencia</th>\n",
              "      <th>sexo</th>\n",
              "      <th>age</th>\n",
              "      <th>fecha_alta</th>\n",
              "      <th>ind_nuevo</th>\n",
              "      <th>antiguedad</th>\n",
              "      <th>indrel</th>\n",
              "      <th>ult_fec_cli_1t</th>\n",
              "      <th>indrel_1mes</th>\n",
              "      <th>tiprel_1mes</th>\n",
              "      <th>indresi</th>\n",
              "      <th>indext</th>\n",
              "      <th>conyuemp</th>\n",
              "      <th>canal_entrada</th>\n",
              "      <th>indfall</th>\n",
              "      <th>tipodom</th>\n",
              "      <th>cod_prov</th>\n",
              "      <th>nomprov</th>\n",
              "      <th>ind_actividad_cliente</th>\n",
              "      <th>renta</th>\n",
              "      <th>segmento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-06-28</td>\n",
              "      <td>15889</td>\n",
              "      <td>F</td>\n",
              "      <td>ES</td>\n",
              "      <td>V</td>\n",
              "      <td>56</td>\n",
              "      <td>1995-01-16</td>\n",
              "      <td>0</td>\n",
              "      <td>256</td>\n",
              "      <td>1</td>\n",
              "      <td>NaT</td>\n",
              "      <td>1.0</td>\n",
              "      <td>A</td>\n",
              "      <td>S</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>KAT</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>28.0</td>\n",
              "      <td>MADRID</td>\n",
              "      <td>1</td>\n",
              "      <td>326124.90</td>\n",
              "      <td>01 - TOP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-06-28</td>\n",
              "      <td>1170544</td>\n",
              "      <td>N</td>\n",
              "      <td>ES</td>\n",
              "      <td>H</td>\n",
              "      <td>36</td>\n",
              "      <td>2013-08-28</td>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>1</td>\n",
              "      <td>NaT</td>\n",
              "      <td>1.0</td>\n",
              "      <td>I</td>\n",
              "      <td>S</td>\n",
              "      <td>N</td>\n",
              "      <td>NaN</td>\n",
              "      <td>KAT</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>ALICANTE</td>\n",
              "      <td>0</td>\n",
              "      <td>NA</td>\n",
              "      <td>02 - PARTICULARES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-06-28</td>\n",
              "      <td>1170545</td>\n",
              "      <td>N</td>\n",
              "      <td>ES</td>\n",
              "      <td>V</td>\n",
              "      <td>22</td>\n",
              "      <td>2013-08-28</td>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>1</td>\n",
              "      <td>NaT</td>\n",
              "      <td>1.0</td>\n",
              "      <td>A</td>\n",
              "      <td>S</td>\n",
              "      <td>N</td>\n",
              "      <td>NaN</td>\n",
              "      <td>KHE</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>15.0</td>\n",
              "      <td>CORUÑA, A</td>\n",
              "      <td>1</td>\n",
              "      <td>NA</td>\n",
              "      <td>03 - UNIVERSITARIO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016-06-28</td>\n",
              "      <td>1170547</td>\n",
              "      <td>N</td>\n",
              "      <td>ES</td>\n",
              "      <td>H</td>\n",
              "      <td>22</td>\n",
              "      <td>2013-08-28</td>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>1</td>\n",
              "      <td>NaT</td>\n",
              "      <td>1.0</td>\n",
              "      <td>I</td>\n",
              "      <td>S</td>\n",
              "      <td>N</td>\n",
              "      <td>NaN</td>\n",
              "      <td>KHE</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>8.0</td>\n",
              "      <td>BARCELONA</td>\n",
              "      <td>0</td>\n",
              "      <td>148402.98</td>\n",
              "      <td>03 - UNIVERSITARIO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-06-28</td>\n",
              "      <td>1170548</td>\n",
              "      <td>N</td>\n",
              "      <td>ES</td>\n",
              "      <td>H</td>\n",
              "      <td>22</td>\n",
              "      <td>2013-08-28</td>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>1</td>\n",
              "      <td>NaT</td>\n",
              "      <td>1.0</td>\n",
              "      <td>I</td>\n",
              "      <td>S</td>\n",
              "      <td>N</td>\n",
              "      <td>NaN</td>\n",
              "      <td>KHE</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>7.0</td>\n",
              "      <td>BALEARS, ILLES</td>\n",
              "      <td>0</td>\n",
              "      <td>106885.80</td>\n",
              "      <td>03 - UNIVERSITARIO</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  fecha_dato  ncodpers ind_empleado pais_residencia sexo  age fecha_alta  \\\n",
              "0 2016-06-28     15889            F              ES    V   56 1995-01-16   \n",
              "1 2016-06-28   1170544            N              ES    H   36 2013-08-28   \n",
              "2 2016-06-28   1170545            N              ES    V   22 2013-08-28   \n",
              "3 2016-06-28   1170547            N              ES    H   22 2013-08-28   \n",
              "4 2016-06-28   1170548            N              ES    H   22 2013-08-28   \n",
              "\n",
              "   ind_nuevo  antiguedad  indrel ult_fec_cli_1t  indrel_1mes tiprel_1mes  \\\n",
              "0          0         256       1            NaT          1.0           A   \n",
              "1          0          34       1            NaT          1.0           I   \n",
              "2          0          34       1            NaT          1.0           A   \n",
              "3          0          34       1            NaT          1.0           I   \n",
              "4          0          34       1            NaT          1.0           I   \n",
              "\n",
              "  indresi indext conyuemp canal_entrada indfall  tipodom  cod_prov  \\\n",
              "0       S      N        N           KAT       N        1      28.0   \n",
              "1       S      N      NaN           KAT       N        1       3.0   \n",
              "2       S      N      NaN           KHE       N        1      15.0   \n",
              "3       S      N      NaN           KHE       N        1       8.0   \n",
              "4       S      N      NaN           KHE       N        1       7.0   \n",
              "\n",
              "          nomprov  ind_actividad_cliente        renta            segmento  \n",
              "0          MADRID                      1    326124.90            01 - TOP  \n",
              "1        ALICANTE                      0           NA   02 - PARTICULARES  \n",
              "2       CORUÑA, A                      1           NA  03 - UNIVERSITARIO  \n",
              "3       BARCELONA                      0    148402.98  03 - UNIVERSITARIO  \n",
              "4  BALEARS, ILLES                      0    106885.80  03 - UNIVERSITARIO  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMeYgUQWZ5CQ",
        "colab_type": "code",
        "outputId": "863a1bd5-6680-4882-feaf-5f07382f2e6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(train_df.shape)\n",
        "print(test_df.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(13647309, 48)\n",
            "(50000, 24)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCsZFs8H02rs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns_num = ['age',\n",
        "               'renta',\n",
        "               'antiguedad',\n",
        "               'ncodpers']\n",
        "\n",
        "columns_cat = ['ind_empleado',\n",
        "               'pais_residencia',   \n",
        "               'sexo',\n",
        "               'ind_nuevo',\n",
        "               'indrel',                    \n",
        "               'tiprel_1mes', \n",
        "               'indresi',\n",
        "               'indrel_1mes',\n",
        "               'indext',\n",
        "               'canal_entrada',     #The encoding creates too much columns, not very relevant (the weights are low)\n",
        "               'conyuemp',           #100% of NaN values (see below)\n",
        "               'indfall',\n",
        "               'nomprov',\n",
        "               'segmento',\n",
        "               'tipodom',\n",
        "               'cod_prov',\n",
        "               'ind_actividad_cliente']\n",
        "\n",
        "columns_date =['fecha_dato',\n",
        "               'fecha_alta',\n",
        "               'ult_fec_cli_1t']    #100% of NaN values (see below)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wN0G9BST02ru",
        "colab_type": "text"
      },
      "source": [
        "# Descriptive Statistics & Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaSv3imz02rv",
        "colab_type": "code",
        "outputId": "80db8aa5-2be5-45c6-d254-ba891e96d6c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        }
      },
      "source": [
        "print(\"age value statistics\", train_df['age'].describe())\n",
        "print(\"\\n \\n \\n renta value statistics \\n\\n\", train_df['renta'].describe())\n",
        "\n",
        "print(\"\\n\\n\\n categorical value statistics \\n\\n\", train_df[columns_cat].describe())\n",
        "print(\"\\n\\n\\n date value statistics \\n\\n\", train_df[columns_date].describe())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "age value statistics count     500000\n",
            "unique       115\n",
            "top           23\n",
            "freq       39228\n",
            "Name: age, dtype: object\n",
            "\n",
            " \n",
            " \n",
            " renta value statistics \n",
            "\n",
            " count    4.110990e+05\n",
            "mean     1.318600e+05\n",
            "std      2.293840e+05\n",
            "min      1.202730e+03\n",
            "25%      6.748633e+04\n",
            "50%      9.982623e+04\n",
            "75%      1.531584e+05\n",
            "max      2.889440e+07\n",
            "Name: renta, dtype: float64\n",
            "\n",
            "\n",
            "\n",
            " categorical value statistics \n",
            "\n",
            "            ncodpers         indrel      ind_nuevo    indrel_1mes   tipodom  \\\n",
            "count  5.000000e+05  494611.000000  494611.000000  494611.000000  494611.0   \n",
            "mean   8.171304e+05       1.130769       0.000303       1.000091       1.0   \n",
            "std    4.381616e+05       3.577475       0.017412       0.013414       0.0   \n",
            "min    1.588900e+04       1.000000       0.000000       1.000000       1.0   \n",
            "25%    3.362618e+05       1.000000       0.000000       1.000000       1.0   \n",
            "50%    9.856585e+05       1.000000       0.000000       1.000000       1.0   \n",
            "75%    1.177883e+06       1.000000       0.000000       1.000000       1.0   \n",
            "max    1.379131e+06      99.000000       1.000000       3.000000       1.0   \n",
            "\n",
            "            cod_prov  ind_actividad_cliente  \n",
            "count  492205.000000          494611.000000  \n",
            "mean       26.395049               0.519503  \n",
            "std        12.844092               0.499620  \n",
            "min         1.000000               0.000000  \n",
            "25%        15.000000               0.000000  \n",
            "50%        28.000000               1.000000  \n",
            "75%        35.000000               1.000000  \n",
            "max        52.000000               1.000000  \n",
            "\n",
            "\n",
            "\n",
            " date value statistics \n",
            "\n",
            "                  fecha_dato           fecha_alta       ult_fec_cli_1t\n",
            "count                500000               494611                  660\n",
            "unique                    1                 5803                   22\n",
            "top     2015-01-28 00:00:00  2014-07-28 00:00:00  2015-07-09 00:00:00\n",
            "freq                 500000                 3278                   52\n",
            "first   2015-01-28 00:00:00  1995-01-16 00:00:00  2015-07-01 00:00:00\n",
            "last    2015-01-28 00:00:00  2015-01-30 00:00:00  2015-07-30 00:00:00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLckxpNq02rx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_dates(datetimes, title):\n",
        "    # Size of figure\n",
        "    plt.figure(figsize=(15,8))\n",
        "\n",
        "    # Plot the values\n",
        "    sns.barplot(\n",
        "        datetimes.index, \n",
        "        datetimes.values,\n",
        "        alpha=0.7,\n",
        "        color=(0, 0, 0.9)\n",
        "    )\n",
        "\n",
        "    # Make labels x: yyyymm format\n",
        "    plt.xlabel('Year and month ', fontsize=16)\n",
        "    plt.ylabel('Number of customers on date', fontsize=16)\n",
        "\n",
        "    # Make xlabel vertical instead of horizontal\n",
        "    plt.xticks(rotation='vertical')\n",
        "    \n",
        "    plt.suptitle(title, fontsize=24)\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "XaxHJiN602r1",
        "colab_type": "code",
        "outputId": "2d3e8600-c3f8-4bbf-d438-ab1f77863c5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 587
        }
      },
      "source": [
        "yearmonth = train_df['fecha_dato'].apply(\n",
        "    lambda x: (100*x.year) + x.month\n",
        ").value_counts()\n",
        "\n",
        "plot_dates(yearmonth, 'Training data - customers')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFieJbhs02r6",
        "colab_type": "code",
        "outputId": "da63f6e0-25bc-4c4e-dcb6-a64d8ebf9b49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 587
        }
      },
      "source": [
        "test_yearmonth = test_df['fecha_dato'].apply(\n",
        "    lambda x: (100*x.year) + x.month\n",
        ").value_counts()\n",
        "\n",
        "plot_dates(test_yearmonth, 'Testing data - customers')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NLy5pKz02r-",
        "colab_type": "text"
      },
      "source": [
        "# Cleaning the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "JBCkD3eO02r_",
        "colab_type": "code",
        "outputId": "cd140422-3be8-4ebd-ec47-e03e871b8f5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(\"Training NaN values percentages \\n\\n\",(train_df.isna().sum()/train_df.shape[0])*100)\n",
        "print(\"\\n\\n Testing NaN values percentages \\n\\n\",(test_df.isna().sum()/test_df.shape[0])*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training NaN values percentages \n",
            "\n",
            " fecha_dato                0.000000\n",
            "ncodpers                  0.000000\n",
            "ind_empleado              0.203220\n",
            "pais_residencia           0.203220\n",
            "sexo                      0.203732\n",
            "age                       0.000000\n",
            "fecha_alta                0.203220\n",
            "ind_nuevo                 0.203220\n",
            "antiguedad                0.000000\n",
            "indrel                    0.203220\n",
            "ult_fec_cli_1t           99.818330\n",
            "indrel_1mes               1.097513\n",
            "tiprel_1mes               1.097513\n",
            "indresi                   0.203220\n",
            "indext                    0.203220\n",
            "conyuemp                 99.986752\n",
            "canal_entrada             1.363829\n",
            "indfall                   0.203220\n",
            "tipodom                   0.203227\n",
            "cod_prov                  0.685784\n",
            "nomprov                   0.685784\n",
            "ind_actividad_cliente     0.203220\n",
            "renta                    20.475648\n",
            "segmento                  1.387585\n",
            "ind_ahor_fin_ult1         0.000000\n",
            "ind_aval_fin_ult1         0.000000\n",
            "ind_cco_fin_ult1          0.000000\n",
            "ind_cder_fin_ult1         0.000000\n",
            "ind_cno_fin_ult1          0.000000\n",
            "ind_ctju_fin_ult1         0.000000\n",
            "ind_ctma_fin_ult1         0.000000\n",
            "ind_ctop_fin_ult1         0.000000\n",
            "ind_ctpp_fin_ult1         0.000000\n",
            "ind_deco_fin_ult1         0.000000\n",
            "ind_deme_fin_ult1         0.000000\n",
            "ind_dela_fin_ult1         0.000000\n",
            "ind_ecue_fin_ult1         0.000000\n",
            "ind_fond_fin_ult1         0.000000\n",
            "ind_hip_fin_ult1          0.000000\n",
            "ind_plan_fin_ult1         0.000000\n",
            "ind_pres_fin_ult1         0.000000\n",
            "ind_reca_fin_ult1         0.000000\n",
            "ind_tjcr_fin_ult1         0.000000\n",
            "ind_valo_fin_ult1         0.000000\n",
            "ind_viv_fin_ult1          0.000000\n",
            "ind_nomina_ult1           0.117701\n",
            "ind_nom_pens_ult1         0.117701\n",
            "ind_recibo_ult1           0.000000\n",
            "dtype: float64\n",
            "\n",
            "\n",
            " Testing NaN values percentages \n",
            "\n",
            " fecha_dato                0.000\n",
            "ncodpers                  0.000\n",
            "ind_empleado              0.000\n",
            "pais_residencia           0.000\n",
            "sexo                      0.000\n",
            "age                       0.000\n",
            "fecha_alta                0.000\n",
            "ind_nuevo                 0.000\n",
            "antiguedad                0.000\n",
            "indrel                    0.000\n",
            "ult_fec_cli_1t           99.884\n",
            "indrel_1mes               0.000\n",
            "tiprel_1mes               0.000\n",
            "indresi                   0.000\n",
            "indext                    0.000\n",
            "conyuemp                 99.998\n",
            "canal_entrada             0.002\n",
            "indfall                   0.000\n",
            "tipodom                   0.000\n",
            "cod_prov                  0.066\n",
            "nomprov                   0.066\n",
            "ind_actividad_cliente     0.000\n",
            "renta                     0.000\n",
            "segmento                  0.006\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbTP3Dx6VrBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nan_value_check(value):\n",
        "    check = str(val).replace(' ', '').lower()\n",
        "    if check == '?' or check == 'na' or check == 'nan':\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOKOqSrW02sB",
        "colab_type": "text"
      },
      "source": [
        "## Removing the obvious features\n",
        "\n",
        "We can clearly see that 'ult_fec_cli_1t' and 'conyuemp' should be removed, because they have almost 100% NaN values, which we cannot use for anything."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NguSG-MH02sB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove columns with too many NaN values\n",
        "drop_features = ['ult_fec_cli_1t', 'conyuemp']\n",
        "#nomprov and cod_prov are the same information, and the encoding creates too many columns\n",
        "drop_features.append('nomprov')\n",
        "drop_features.append('cod_prov')\n",
        "#tipodom has only one value\n",
        "drop_features.append('tipodom')\n",
        "#the encoding of canal_entrada and pais_residencia creates too many columns\n",
        "drop_features.append('canal_entrada')\n",
        "drop_features.append('pais_residencia')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4fE4jB102sF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = train_df.drop(drop_features, axis=1)\n",
        "test_df = test_df.drop(drop_features, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjmObaDp02sJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns_date.remove(drop_features[0])\n",
        "columns_cat.remove(drop_features[1])\n",
        "columns_cat.remove(drop_features[2])\n",
        "columns_cat.remove(drop_features[3])\n",
        "columns_cat.remove(drop_features[4])\n",
        "columns_cat.remove(drop_features[5])\n",
        "columns_cat.remove(drop_features[6])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68wt3dgR02sM",
        "colab_type": "text"
      },
      "source": [
        "## The feature 'renta'\n",
        "\n",
        "This feature has nan values, but not enough to where we want to drop it. Instead, we choose to prepare it for imputation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXrrVByO02sM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make nan values into numpy nan values\n",
        "train_df['renta'] = train_df['renta'].fillna(np.nan)\n",
        "\n",
        "# test data is type object\n",
        "new_vals = []\n",
        "for val in test_df['renta']:\n",
        "    if nan_value_check(val):\n",
        "        val = np.nan\n",
        "    new_vals.append(val)\n",
        "    \n",
        "test_df['renta'] = np.array(new_vals, dtype=float)\n",
        "\n",
        "###test_df['renta'] = test_df['renta'].fillna(np.nan) why not only this line ?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qcZmrHT02sP",
        "colab_type": "text"
      },
      "source": [
        "We have chosen to impute the values for renta, since the feature could potentially have good predictive power, in terms of which products a customer might want to purchase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQacRoAA02sP",
        "colab_type": "code",
        "outputId": "d5a745fb-c20f-4385-eec2-f823d509d38e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print(\"Number of Nan values in column renta before the process:\")\n",
        "print(train_df['renta'].isna().sum())\n",
        "print(test_df['renta'].isna().sum())\n",
        "\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
        "train_df['renta'] = imputer.fit_transform(train_df['renta'].values.reshape(-1, 1))\n",
        "\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
        "test_df['renta'] = imputer.fit_transform(test_df['renta'].values.reshape(-1, 1))\n",
        "\n",
        "print(\"\\nAfter the imputation:\")\n",
        "print(train_df['renta'].isna().sum())\n",
        "print(test_df['renta'].isna().sum())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Nan values in column renta before the process:\n",
            "2794375\n",
            "9779\n",
            "\n",
            "After the imputation:\n",
            "0\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4VGPHTW02sS",
        "colab_type": "text"
      },
      "source": [
        "## The rest of the data\n",
        "\n",
        "We choose to drop the rest of the rows that contains NaN values, since we can see that it is such a small percentage that it won't matter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6EdN41sCWDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['age'] = train_df['age'].str.strip()\n",
        "train_df['antiguedad'] = train_df['antiguedad'].str.strip()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCARkbqj02sS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = train_df.dropna(axis=0, how='any')\n",
        "test_df = test_df.dropna(axis=0, how='any')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ke0JJLPsCppr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['age'] = train_df['age'].astype(np.float64)\n",
        "train_df['antiguedad'] = train_df['antiguedad'].astype(np.float64)\n",
        "test_df['age'] = test_df['age'].astype(np.float64)\n",
        "test_df['antiguedad'] = test_df['antiguedad'].astype(np.float64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rd0N5-heje0B",
        "colab_type": "text"
      },
      "source": [
        "## The feature \"indrel_1mes\"\n",
        "\n",
        "This feature can take only 5 different values, but actually, we can more types because some of the numbers are \"float\" while others are \"string\".\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYaHmLHYj2hm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_vals = []\n",
        "for val in test_df[\"indrel_1mes\"]:\n",
        "  if type(val)=='str':\n",
        "    val = float(val)\n",
        "  new_vals.append(val)\n",
        "test_df[\"indrel_1mes\"] = np.array(new_vals, dtype=float)\n",
        "\n",
        "new_vals = []\n",
        "for val in train_df[\"indrel_1mes\"]:\n",
        "  if type(val)=='str':\n",
        "    val = float(val)\n",
        "  new_vals.append(val)\n",
        "train_df[\"indrel_1mes\"] = np.array(new_vals, dtype=float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V54RADq302sW",
        "colab_type": "text"
      },
      "source": [
        "## A quick check on the total number of NaN values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lUnEAKG02sW",
        "colab_type": "code",
        "outputId": "23f94ffd-3d59-4743-911c-3aca8588c551",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "source": [
        "train_nan_values = 0\n",
        "test_nan_values = 0\n",
        "\n",
        "for name, values in train_df.iteritems():\n",
        "    for val in values:\n",
        "        if nan_value_check(val):\n",
        "            train_nan_values += 1\n",
        "\n",
        "for name, values in test_df.iteritems():\n",
        "    for val in values:\n",
        "        if nan_value_check(val):\n",
        "            test_nan_values += 1\n",
        "            \n",
        "print(f'There are {train_nan_values} NaN values in training dataset')\n",
        "print(f'There are {test_nan_values} NaN values in testing dataset')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-a915539aff1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnan_value_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mtrain_nan_values\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mmaybe_box_datetimelike\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtslibs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtslibs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRYzrRxQ02sa",
        "colab_type": "text"
      },
      "source": [
        "# Preparing X and Y values\n",
        "\n",
        "In this section, we want to prepare our inputs and outputs of the model. In particular, we want to include the prior information of which products the customer is already paying for."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8T-_NbeT02sa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_variables = ['ind_ahor_fin_ult1', 'ind_aval_fin_ult1',\n",
        "       'ind_cco_fin_ult1', 'ind_cder_fin_ult1', 'ind_cno_fin_ult1',\n",
        "       'ind_ctju_fin_ult1', 'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1',\n",
        "       'ind_ctpp_fin_ult1', 'ind_deco_fin_ult1', 'ind_deme_fin_ult1',\n",
        "       'ind_dela_fin_ult1', 'ind_ecue_fin_ult1', 'ind_fond_fin_ult1',\n",
        "       'ind_hip_fin_ult1', 'ind_plan_fin_ult1', 'ind_pres_fin_ult1',\n",
        "       'ind_reca_fin_ult1', 'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1',\n",
        "       'ind_viv_fin_ult1', 'ind_nomina_ult1', 'ind_nom_pens_ult1',\n",
        "       'ind_recibo_ult1']\n",
        "\n",
        "y_train = train_df[y_variables]\n",
        "X_train = train_df\n",
        "X_test = test_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9onLwI9_02sf",
        "colab_type": "text"
      },
      "source": [
        "## Encoding the dataset\n",
        "\n",
        "To be able to use our dataset, we must encode all features, so that they appear as numbers instead of strings, datetimes, or other datatypes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsLztGMg02sf",
        "colab_type": "text"
      },
      "source": [
        "### Columns of type 'object'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdswoVzun_E3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_cat = np.concatenate([pd.get_dummies(X_train[x]) for x in columns_cat], axis=1)\n",
        "#print(X_cat.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ujTG7IQi02sf",
        "colab_type": "code",
        "outputId": "31aca2ed-3707-4591-8b35-add44b72b056",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "totaltrain = 0\n",
        "totaltest = 0\n",
        "for column in columns_cat:\n",
        "\n",
        "  train_cat_encoded = pd.get_dummies(X_train[column])\n",
        "  test_cat_encoded = pd.get_dummies(X_test[column])\n",
        "  L = []\n",
        "  J = []\n",
        "  #print(\"___\")\n",
        "  totaltrain += train_cat_encoded.shape[1]\n",
        "  totaltest += test_cat_encoded.shape[1]\n",
        "  print(column)\n",
        "  print(train_cat_encoded.shape[1])\n",
        "  print(test_cat_encoded.shape[1])\n",
        "print(totaltrain)\n",
        "print(totaltest)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ind_empleado\n",
            "5\n",
            "2\n",
            "sexo\n",
            "2\n",
            "2\n",
            "ind_nuevo\n",
            "2\n",
            "2\n",
            "indrel\n",
            "2\n",
            "2\n",
            "tiprel_1mes\n",
            "3\n",
            "2\n",
            "indresi\n",
            "2\n",
            "2\n",
            "indrel_1mes\n",
            "2\n",
            "1\n",
            "indext\n",
            "2\n",
            "2\n",
            "indfall\n",
            "2\n",
            "2\n",
            "segmento\n",
            "3\n",
            "3\n",
            "ind_actividad_cliente\n",
            "2\n",
            "2\n",
            "27\n",
            "22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HPAKOZ002sh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.drop(columns_cat, axis=1)\n",
        "X_test = X_test.drop(columns_cat, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuHBHnE_eVoA",
        "colab_type": "text"
      },
      "source": [
        "Here, there is a problam because the number of columns in test_cat_encoded is bigger than the numberof clums in train_cat_encoded, but it's important that our two dataset have the same number of columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtytbh2102sj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = pd.concat([X_train, train_cat_encoded], axis=1)\n",
        "X_test = pd.concat([X_test, test_cat_encoded], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1iAw4TV02st",
        "colab_type": "text"
      },
      "source": [
        "### Columns of type 'datetime64'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8OJ3fKn02st",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def datetime_to_features(timestamp):\n",
        "    year = timestamp.year\n",
        "    month = timestamp.month\n",
        "    day = timestamp.day\n",
        "    \n",
        "    return year, month, day"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYqhV5PL02sv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def datetimes_to_features(dt_features):\n",
        "    data = pd.DataFrame()\n",
        "    for name, values in dt_features.iteritems():\n",
        "        year = []\n",
        "        month = []\n",
        "        day = []\n",
        "\n",
        "        for val in values:\n",
        "            y,m,d = datetime_to_features(val)\n",
        "            year.append(y) ; month.append(m) ; day.append(d)\n",
        "\n",
        "        new_features = {name + '_year'  : year,\n",
        "                        name + '_month' : month,\n",
        "                        name + '_day'   : day}\n",
        "        \n",
        "        new_data = pd.DataFrame(new_features)\n",
        "        data = pd.concat([data, new_data], axis=1)\n",
        "        \n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zhAvBv-02s0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_new_features = datetimes_to_features(X_train[columns_date])\n",
        "test_new_features = datetimes_to_features(X_test[columns_date])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DokhwCyc46Zg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.drop(columns_date, axis=1)\n",
        "X_test = X_test.drop(columns_date, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y84pRvP602s3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reset_index(drop=True)\n",
        "X_test = X_test.reset_index(drop=True)\n",
        "X_train = pd.concat([X_train, train_new_features], axis=1)\n",
        "X_test = pd.concat([X_test, test_new_features], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtGKCTsM02tL",
        "colab_type": "text"
      },
      "source": [
        "### Checking Column Equality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SDPwgNp02tL",
        "colab_type": "code",
        "outputId": "be491720-f780-446b-9538-0c94951121fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "not_in_test = []\n",
        "for col in X_train.columns:\n",
        "    if col not in X_test.columns and col not in y_variables:\n",
        "        not_in_test.append(col)\n",
        "        \n",
        "print(not_in_test)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJQ9O-VI02tN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.drop(not_in_test, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suv3FT17utPW",
        "colab_type": "code",
        "outputId": "a3608aa4-255a-4bf5-ddd4-002bc21572c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(982056, 36)\n",
            "(982056, 24)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iI_ajrwt02tR",
        "colab_type": "code",
        "outputId": "788e3654-b8fc-4e6d-9ae5-06660f01d34b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "X_train.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ncodpers</th>\n",
              "      <th>age</th>\n",
              "      <th>antiguedad</th>\n",
              "      <th>renta</th>\n",
              "      <th>ind_ahor_fin_ult1</th>\n",
              "      <th>ind_aval_fin_ult1</th>\n",
              "      <th>ind_cco_fin_ult1</th>\n",
              "      <th>ind_cder_fin_ult1</th>\n",
              "      <th>ind_cno_fin_ult1</th>\n",
              "      <th>ind_ctju_fin_ult1</th>\n",
              "      <th>ind_ctma_fin_ult1</th>\n",
              "      <th>ind_ctop_fin_ult1</th>\n",
              "      <th>ind_ctpp_fin_ult1</th>\n",
              "      <th>ind_deco_fin_ult1</th>\n",
              "      <th>ind_deme_fin_ult1</th>\n",
              "      <th>ind_dela_fin_ult1</th>\n",
              "      <th>ind_ecue_fin_ult1</th>\n",
              "      <th>ind_fond_fin_ult1</th>\n",
              "      <th>ind_hip_fin_ult1</th>\n",
              "      <th>ind_plan_fin_ult1</th>\n",
              "      <th>ind_pres_fin_ult1</th>\n",
              "      <th>ind_reca_fin_ult1</th>\n",
              "      <th>ind_tjcr_fin_ult1</th>\n",
              "      <th>ind_valo_fin_ult1</th>\n",
              "      <th>ind_viv_fin_ult1</th>\n",
              "      <th>ind_nomina_ult1</th>\n",
              "      <th>ind_nom_pens_ult1</th>\n",
              "      <th>ind_recibo_ult1</th>\n",
              "      <th>0.0</th>\n",
              "      <th>1.0</th>\n",
              "      <th>fecha_dato_year</th>\n",
              "      <th>fecha_dato_month</th>\n",
              "      <th>fecha_dato_day</th>\n",
              "      <th>fecha_alta_year</th>\n",
              "      <th>fecha_alta_month</th>\n",
              "      <th>fecha_alta_day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1375586</td>\n",
              "      <td>35.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>87218.10000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1050611</td>\n",
              "      <td>23.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>35548.74000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>2012</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1050612</td>\n",
              "      <td>23.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>122179.11000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>2012</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1050613</td>\n",
              "      <td>22.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>119775.54000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>2012</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1050614</td>\n",
              "      <td>23.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>139646.15094</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>2012</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ncodpers   age  antiguedad         renta  ind_ahor_fin_ult1  \\\n",
              "0   1375586  35.0         6.0   87218.10000                  0   \n",
              "1   1050611  23.0        35.0   35548.74000                  0   \n",
              "2   1050612  23.0        35.0  122179.11000                  0   \n",
              "3   1050613  22.0        35.0  119775.54000                  0   \n",
              "4   1050614  23.0        35.0  139646.15094                  0   \n",
              "\n",
              "   ind_aval_fin_ult1  ind_cco_fin_ult1  ind_cder_fin_ult1  ind_cno_fin_ult1  \\\n",
              "0                  0                 1                  0                 0   \n",
              "1                  0                 1                  0                 0   \n",
              "2                  0                 1                  0                 0   \n",
              "3                  0                 0                  0                 0   \n",
              "4                  0                 1                  0                 0   \n",
              "\n",
              "   ind_ctju_fin_ult1  ind_ctma_fin_ult1  ind_ctop_fin_ult1  ind_ctpp_fin_ult1  \\\n",
              "0                  0                  0                  0                  0   \n",
              "1                  0                  0                  0                  0   \n",
              "2                  0                  0                  0                  0   \n",
              "3                  0                  0                  0                  0   \n",
              "4                  0                  0                  0                  0   \n",
              "\n",
              "   ind_deco_fin_ult1  ind_deme_fin_ult1  ind_dela_fin_ult1  ind_ecue_fin_ult1  \\\n",
              "0                  0                  0                  0                  0   \n",
              "1                  0                  0                  0                  0   \n",
              "2                  0                  0                  0                  0   \n",
              "3                  1                  0                  0                  0   \n",
              "4                  0                  0                  0                  0   \n",
              "\n",
              "   ind_fond_fin_ult1  ind_hip_fin_ult1  ind_plan_fin_ult1  ind_pres_fin_ult1  \\\n",
              "0                  0                 0                  0                  0   \n",
              "1                  0                 0                  0                  0   \n",
              "2                  0                 0                  0                  0   \n",
              "3                  0                 0                  0                  0   \n",
              "4                  0                 0                  0                  0   \n",
              "\n",
              "   ind_reca_fin_ult1  ind_tjcr_fin_ult1  ind_valo_fin_ult1  ind_viv_fin_ult1  \\\n",
              "0                  0                  0                  0                 0   \n",
              "1                  0                  0                  0                 0   \n",
              "2                  0                  0                  0                 0   \n",
              "3                  0                  0                  0                 0   \n",
              "4                  0                  0                  0                 0   \n",
              "\n",
              "   ind_nomina_ult1  ind_nom_pens_ult1  ind_recibo_ult1  0.0  1.0  \\\n",
              "0              0.0                0.0                0    0    1   \n",
              "1              0.0                0.0                0    1    0   \n",
              "2              0.0                0.0                0    1    0   \n",
              "3              0.0                0.0                0    1    0   \n",
              "4              0.0                0.0                0    0    1   \n",
              "\n",
              "   fecha_dato_year  fecha_dato_month  fecha_dato_day  fecha_alta_year  \\\n",
              "0             2015                 1              28             2015   \n",
              "1             2015                 1              28             2012   \n",
              "2             2015                 1              28             2012   \n",
              "3             2015                 1              28             2012   \n",
              "4             2015                 1              28             2012   \n",
              "\n",
              "   fecha_alta_month  fecha_alta_day  \n",
              "0                 1              12  \n",
              "1                 8              10  \n",
              "2                 8              10  \n",
              "3                 8              10  \n",
              "4                 8              10  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 390
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5X8o_T5x02tU",
        "colab_type": "text"
      },
      "source": [
        "### Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EmOd6ey02ta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ncodpers = X_test['ncodpers'].values\n",
        "\n",
        "pred_df = pd.DataFrame({'ncodpers':ncodpers, 'added_products': predictions})\n",
        "pred_df.to_csv('data/predictions.csv', columns=pred_df.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EdsMF6a14hPv"
      },
      "source": [
        "#Functions to assess the accuracy of the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DBbIhsy44hPx"
      },
      "source": [
        "For the general accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LMNzCxAn4hPy",
        "colab": {}
      },
      "source": [
        "def accuracy(y_hat, y_test):\n",
        "  return 1.0*np.sum(y_hat == y_test) / len(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xdh0kWH14hP4"
      },
      "source": [
        "Then, we check the number of times where a customer has bought a product, and if this product has been predicted by the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iddW-uVl4hP5",
        "colab": {}
      },
      "source": [
        "def accuracy_2(y_hat, y_test):\n",
        "  correct = 0\n",
        "  for i in range(len(y_test)):\n",
        "    if y_test[i] == 1:\n",
        "      correct += y_hat[i]\n",
        "\n",
        "  if sum(y_test) > 0:\n",
        "    return 1.0*correct/sum(y_test)\n",
        "  else:\n",
        "    return \"This product has never been bought by the customers, and has been predicted \\\"bought\\\" \" + str(sum(y_hat)) + \" times by the model\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_5LH77504hP8"
      },
      "source": [
        "Finally, we count the number of times where we have predicted something, and this prediction was correct"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8kpee2kI4hP8",
        "colab": {}
      },
      "source": [
        "def accuracy_model(y_hat, y_test):\n",
        "  correct = 0\n",
        "  for i in range(len(y_hat)):\n",
        "    if y_hat[i] == 1:\n",
        "      correct += y_test[i]\n",
        "      \n",
        "  if sum(y_hat) > 0:\n",
        "    return 1.0*correct/sum(y_hat)\n",
        "  else:\n",
        "    return \"This product has never been predicted as bought by the model, and has been bought \" + str(sum(y_test)) + \" times by the customers\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Hnz-IKLt4hP-"
      },
      "source": [
        "This function will compute the accuracy of a full line of predictions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IuLT7hPz4hP_",
        "colab": {}
      },
      "source": [
        "def accuracy_full_line(y_hat, y_test):\n",
        "  correct = 0\n",
        "  nb_products = len(y_hat[1])\n",
        "  for i in range(len(y_hat)):\n",
        "    test = 0\n",
        "    for j in range(nb_products):\n",
        "      test += (y_hat[i][j] == y_test[i][j])\n",
        "    if test == nb_products:\n",
        "      correct += 1\n",
        "  return correct/len(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3uqkD_A04hQD"
      },
      "source": [
        "Thess functions return the accuracy of the predictions by products for each line"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lBDEK9VB4hQE",
        "colab": {}
      },
      "source": [
        "def accuracy_by_product(y_hat, y_test):\n",
        "  E = []\n",
        "  for i in range(len(y_hat[1])):\n",
        "    E.append(accuracy(y_hat[:,i],y_test[:,i]))\n",
        "  return E\n",
        "\n",
        "def accuracy_2_by_product(y_hat, y_test):\n",
        "  E = []\n",
        "  for i in range(len(y_hat[1])):\n",
        "    E.append(accuracy_2(y_hat[:,i],y_test[:,i]))\n",
        "  return E\n",
        "\n",
        "def accuracy_model_by_product(y_hat, y_test):\n",
        "  E = []\n",
        "  for i in range(len(y_hat[1])):\n",
        "    E.append(accuracy_model(y_hat[:,i],y_test[:,i]))\n",
        "  return E"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XF9U79XbzTt3",
        "colab_type": "text"
      },
      "source": [
        "#Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2DYVTGMkWbH",
        "colab_type": "code",
        "outputId": "62d44776-3671-40d4-fce3-1249fe59aa51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Need to change this later, and to take into account all the features\n",
        "X_cat = np.concatenate([pd.get_dummies(train_df[x]) for x in columns_cat], axis=1)\n",
        "#We don't need the codpers to make predictions based on the profile\n",
        "X_num = train_df[columns_num[:-1]]\n",
        "X = np.concatenate([X_cat, X_num], axis=1)\n",
        "print(X.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(989027, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DooozBxkY1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# standardize input features\n",
        "X_mean = X.mean(axis=0)\n",
        "X_std = X.std(axis=0)\n",
        "X = (X - X_mean) / X_std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLffu40AyFzE",
        "colab_type": "text"
      },
      "source": [
        "###For only one product: (product number 7)\n",
        "For this first example, we just try to predict for one product, and the prediction is based on the features in \"columns_cat\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeWnUDMKs2xZ",
        "colab_type": "code",
        "outputId": "81366c59-b3c9-4345-f040-4a0d23eb877c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "mat = train_df[y_variables].values\n",
        "Y = mat[:,7].astype(\"int\")\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "print(\"number of 1 values :\", sum(Y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(989027, 30)\n",
            "(989027,)\n",
            "number of 1 values : 211687\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8X0cVcy8kaYT",
        "colab_type": "code",
        "outputId": "aef80637-ae7e-4784-88ff-539197c66f3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#Train/test split\n",
        "train_perc = 0.75 # percentage of training data\n",
        "split_point = int(train_perc*len(Y))\n",
        "perm = np.random.permutation(len(Y))\n",
        "ix_train = perm[:split_point]\n",
        "ix_test = perm[split_point:]\n",
        "X_train = X[ix_train,:]\n",
        "X_test = X[ix_test,:]\n",
        "Y_train = Y[ix_train]\n",
        "Y_test = Y[ix_test]\n",
        "print(\"num train: %d\" % len(Y_train))\n",
        "print(\"num test: %d\" % len(Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num train: 741770\n",
            "num test: 247257\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pNWFTLtkcB4",
        "colab_type": "code",
        "outputId": "9066bd56-16b7-4120-cba1-b639c2cad362",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# create and fit logistic regression model\n",
        "logreg = linear_model.LogisticRegression(solver='lbfgs', multi_class='auto', max_iter = 5000)\n",
        "logreg.fit(X_train, Y_train)\n",
        "\n",
        "# make predictions for test set\n",
        "Y_hat = logreg.predict(X_test)\n",
        "print(\"predictions:\", Y_hat)\n",
        "print(\"true values:\", Y_test)\n",
        "\n",
        "# evaluate prediction accuracy\n",
        "print(\"Accuracy:\", 1.0*np.sum(Y_hat == Y_test) / len(Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predictions: [0 0 0 ... 0 1 0]\n",
            "true values: [0 0 0 ... 0 1 0]\n",
            "Accuracy: 0.7674848437051327\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qHXjF9akh0W",
        "colab_type": "code",
        "outputId": "67c2e216-aac9-43f8-9ecf-4b159b3c8594",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(sum(Y_hat))\n",
        "print(sum(Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29559\n",
            "52930\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLClnM9dyLmx",
        "colab_type": "text"
      },
      "source": [
        "###For all the products:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELyR2P7SyNK8",
        "colab_type": "code",
        "outputId": "64d29c41-963d-49bb-9f31-df45b639bd11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "mat = train_df[y_variables].values\n",
        "Y = mat[:].astype(\"int\")\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(989027, 30)\n",
            "(989027, 24)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEDKSpKQyUwo",
        "colab_type": "code",
        "outputId": "61354e85-43e3-4a99-9bb5-9d3fd5406ce5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#Train/test split\n",
        "train_perc = 0.75 # percentage of training data\n",
        "split_point = int(train_perc*len(Y))\n",
        "perm = np.random.permutation(len(Y))\n",
        "ix_train = perm[:split_point]\n",
        "ix_test = perm[split_point:]\n",
        "X_train = X[ix_train,:]\n",
        "X_test = X[ix_test,:]\n",
        "Y_train = Y[ix_train]\n",
        "Y_test = Y[ix_test]\n",
        "print(\"num train: %d\" % len(Y_train))\n",
        "print(\"num test: %d\" % len(Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num train: 741770\n",
            "num test: 247257\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUdLV7C_yiNy",
        "colab_type": "code",
        "outputId": "d37e7ed8-e93e-4f31-969a-e86af48794cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dtc = DecisionTreeClassifier()\n",
        "dtc.fit(X_train, Y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 247
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmbmBXlfy5mE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_hat = dtc.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5Tgs4YIbNFN",
        "colab_type": "code",
        "outputId": "afcdff59-ea34-4a15-8ee7-fef45debc64f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "print(accuracy_full_line(Y_hat, Y_test))\n",
        "print(accuracy_by_product(Y_hat, Y_test))\n",
        "print(accuracy_2_by_product(Y_hat, Y_test))\n",
        "print(accuracy_model_by_product(Y_hat, Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7257347618065414\n",
            "[0.9999555118763068, 0.9999919112502376, 0.8799750866507319, 0.9996360062606923, 0.9379107568238715, 0.9996926275090291, 0.9901115034154746, 0.9348248987895186, 0.9688866240389554, 0.9974722656992522, 0.9978888363120154, 0.9660636503718802, 0.9405032011227185, 0.9845262217045423, 0.9945198720359788, 0.9918182296153395, 0.9975086650731829, 0.9613519536352864, 0.9542500313439053, 0.9787872537481245, 0.9963074857334676, 0.949323982738608, 0.9447983272465491, 0.9021827491233817]\n",
            "[0.7692307692307693, 0.875, 0.9187685738501646, 0.5918367346938775, 0.6928834682168775, 0.9884921805842432, 0.4924, 0.8385700846660396, 0.7730133752950433, 0.4377431906614786, 0.6582597730138714, 0.734344894026975, 0.7101222903729666, 0.7051739518287243, 0.7023519870235199, 0.7041678016889131, 0.6691449814126395, 0.7148928737773638, 0.6344112115512953, 0.7144740845927579, 0.7064555420219245, 0.6275310437409106, 0.6364461018999144, 0.6905862144049548]\n",
            "[0.9375, 1.0, 0.9217798922549499, 0.7435897435897436, 0.7149970594001176, 0.9890758783584293, 0.5114250103863731, 0.8553881585260532, 0.7901085645355851, 0.40106951871657753, 0.6752910737386805, 0.7540030911901082, 0.7241084608810504, 0.720163984208928, 0.736081597960051, 0.7339579784213515, 0.7346938775510204, 0.7249380092100602, 0.6642317220351902, 0.7435085497150095, 0.7291011942174733, 0.6564657694558221, 0.6624527906000839, 0.7146541148193586]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0A2YKvO3yioC",
        "colab_type": "text"
      },
      "source": [
        "#And now we will use Pyro. First model: predictions for one product based on the profile of the customers\n",
        "\n",
        "First we use Pyro for one product"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOfbU0Ras8oI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Need to change this later, and to take into account all the features\n",
        "X_cat = np.concatenate([pd.get_dummies(train_df[x]) for x in columns_cat], axis=1)\n",
        "#We don't need the codpers to make predictions based on the profile\n",
        "X_num = train_df[columns_num[:-1]]\n",
        "X = np.concatenate([X_cat, X_num], axis=1)\n",
        "# standardize input features\n",
        "X_mean = X.mean(axis=0)\n",
        "X_std = X.std(axis=0)\n",
        "X = (X - X_mean) / X_std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hz9iT1XZs_GS",
        "colab_type": "code",
        "outputId": "923e5201-cd01-4f61-c1a8-9de725f3054f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "mat = train_df[y_variables].values\n",
        "Y = mat[:].astype(\"int\")\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3756556, 30)\n",
            "(3756556, 24)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "665r8vwguIqy",
        "colab_type": "code",
        "outputId": "517b880a-3013-4b4e-faab-485e765e61d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#Train/test split\n",
        "train_perc = 0.75 # percentage of training data\n",
        "split_point = int(train_perc*len(Y))\n",
        "perm = np.random.permutation(len(Y))\n",
        "ix_train = perm[:split_point]\n",
        "ix_test = perm[split_point:]\n",
        "X_train = X[ix_train,:]\n",
        "X_test = X[ix_test,:]\n",
        "Y_train = Y[ix_train]\n",
        "Y_test = Y[ix_test]\n",
        "print(\"num train: %d\" % len(Y_train))\n",
        "print(\"num test: %d\" % len(Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num train: 2817417\n",
            "num test: 939139\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxhV7xh6kjQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def first_model(X, obs=None):\n",
        "    input_dim = X.shape[1]\n",
        "    n_cat = 2\n",
        "\n",
        "    alpha = pyro.sample(\"alpha\", dist.Normal(torch.zeros(1, n_cat), 5.*torch.ones(1, n_cat)))  # Prior for the bias/intercept\n",
        "    beta  = pyro.sample(\"beta\", dist.Normal(torch.zeros(input_dim, n_cat), 5.*torch.ones(input_dim, n_cat))) # Priors for the regression coeffcients\n",
        "    \n",
        "    \n",
        "    with pyro.plate(\"data\"):\n",
        "      y = pyro.sample(\"y\", dist.Categorical(logits=alpha + X.matmul(beta)), obs=obs)\n",
        "        \n",
        "    return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwmHM6JDkkwF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare data for Pyro\n",
        "X_train = torch.tensor(X_train).float()\n",
        "Y_train = torch.tensor(Y_train).float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJJuCPOwkmNf",
        "colab_type": "code",
        "outputId": "58b69b27-fa56-4c52-cbf4-5df769eb64d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "# Define guide function\n",
        "guide = AutoDiagonalNormal(first_model)\n",
        "\n",
        "# Reset parameter values\n",
        "pyro.clear_param_store()\n",
        "\n",
        "# Define the number of optimization steps\n",
        "n_steps = 5000\n",
        "\n",
        "# Setup the optimizer\n",
        "adam_params = {\"lr\": 0.001}\n",
        "optimizer = ClippedAdam(adam_params)\n",
        "\n",
        "# Setup the inference algorithm\n",
        "elbo = Trace_ELBO(num_particles=1)\n",
        "svi = SVI(first_model, guide, optimizer, loss=elbo)\n",
        "\n",
        "# Do gradient steps\n",
        "for step in range(n_steps):\n",
        "    elbo = svi.step(X_train, Y_train[:,7])\n",
        "    if step % 500 == 0:\n",
        "        print(\"[%d] ELBO: %.1f\" % (step, elbo))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0] ELBO: 11154163.3\n",
            "[500] ELBO: 5413570.1\n",
            "[1000] ELBO: 1818106.2\n",
            "[1500] ELBO: 1109255.5\n",
            "[2000] ELBO: 1031153.9\n",
            "[2500] ELBO: 996176.1\n",
            "[3000] ELBO: 977484.0\n",
            "[3500] ELBO: 961824.8\n",
            "[4000] ELBO: 952058.8\n",
            "[4500] ELBO: 953506.7\n",
            "CPU times: user 1h 4min 22s, sys: 20.5 s, total: 1h 4min 43s\n",
            "Wall time: 31min 4s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBJ1yd9AkpOW",
        "colab_type": "text"
      },
      "source": [
        "Once converged, let's extract the posterior samples for the latent variables in the model using Pyro's Predictive class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVWI4DrwkrTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyro.infer import Predictive\n",
        "\n",
        "predictive = Predictive(first_model, guide=guide, num_samples=2000,\n",
        "                        return_sites=(\"beta\", \"alpha\"))\n",
        "samples = predictive(X_train, Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgzwT2BPks-w",
        "colab_type": "text"
      },
      "source": [
        "Lets plot the posterior distributions of the parameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5ehb5a_kyM0",
        "colab_type": "code",
        "outputId": "0f511908-f305-4a83-d23e-98877b16919d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "beta_samples = samples[\"beta\"].detach().numpy()\n",
        "alpha_samples = samples[\"alpha\"].detach().numpy()\n",
        "print(beta_samples.shape)\n",
        "print(alpha_samples.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2000, 82, 2)\n",
            "(2000, 1, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jDw-EInkzk7",
        "colab_type": "code",
        "outputId": "ac23e5f3-0581-40ca-f71c-69413fec619c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "#attempt to plot the beta, not very successful, there are too much beta\n",
        "for c in range(beta_samples.shape[1]):\n",
        "    sns.distplot(beta_samples[:,c])\n",
        "#plt.legend([\"beta[%d]\" % c for c in range(119)])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CS8CK1_Zk6SE",
        "colab_type": "text"
      },
      "source": [
        "We can now use the inferred posteriors to make predictions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uvq03Bghk36E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# extract expected values of the parameters\n",
        "alpha_hat = samples[\"alpha\"].mean(axis=0).detach().numpy()\n",
        "beta_hat = samples[\"beta\"].mean(axis=0).detach().numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahjY5Q-Xk5C7",
        "colab_type": "code",
        "outputId": "22b2bfec-5747-44fe-b607-7cb5a7ad051a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# make predictions for test set\n",
        "Y_hat = alpha_hat + np.dot(X_test, beta_hat)\n",
        "Y_hat = np.argmax(Y_hat, axis=1)\n",
        "\n",
        "print(accuracy(Y_hat, Y_test[:,7]))\n",
        "print(accuracy_2(Y_hat, Y_test[:,7]))\n",
        "print(accuracy_model(Y_hat, Y_test[:,7]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7870110856315493\n",
            "0.03697102988017594\n",
            "0.5106048703849175\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZME1STCzm66",
        "colab_type": "code",
        "outputId": "44371a87-a4f0-45ed-9ee0-ed1b29b15e73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# make predictions for test set with all the lines\n",
        "Y_hat = alpha_hat + np.dot(X_test, beta_hat)\n",
        "Y_hat = np.argmax(Y_hat, axis=1)\n",
        "\n",
        "print(accuracy(Y_hat, Y_test[:,7]))\n",
        "print(accuracy_2(Y_hat, Y_test[:,7]))\n",
        "print(accuracy_model(Y_hat, Y_test[:,7]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8334985555918772\n",
            "0.06615119733099564\n",
            "0.5583710407239819\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5O7nbPI_ns8E",
        "colab_type": "text"
      },
      "source": [
        "#Second model: predictions for all the products based on the profile of the customers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn0nOcBm_ukL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Need to change this later, and to take into account all the features\n",
        "X_cat = np.concatenate([pd.get_dummies(train_df[x]) for x in columns_cat], axis=1)\n",
        "#We don't need the codpers to make predictions based on the profile\n",
        "X_num = train_df[columns_num[:-1]]\n",
        "X = np.concatenate([X_cat, X_num], axis=1)\n",
        "# standardize input features\n",
        "X_mean = X.mean(axis=0)\n",
        "X_std = X.std(axis=0)\n",
        "X = (X - X_mean) / X_std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leQchlvWomAI",
        "colab_type": "code",
        "outputId": "1e2d0746-6499-4032-83b1-62d952d6509f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "mat = train_df[y_variables].values\n",
        "Y = mat[:].astype(\"int\")\n",
        "print(X.shape)\n",
        "print(Y.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(989027, 30)\n",
            "(989027, 24)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Gkzn-dKorNW",
        "colab_type": "code",
        "outputId": "0b105769-e4dc-429a-e2f0-cf6f84bb650e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#Train/test split\n",
        "train_perc = 0.75 # percentage of training data\n",
        "split_point = int(train_perc*len(Y))\n",
        "perm = np.random.permutation(len(Y))\n",
        "ix_train = perm[:split_point]\n",
        "ix_test = perm[split_point:]\n",
        "X_train = X[ix_train,:]\n",
        "X_test = X[ix_test,:]\n",
        "Y_train = Y[ix_train]\n",
        "Y_test = Y[ix_test]\n",
        "print(\"num train: %d\" % len(Y_train))\n",
        "print(\"num test: %d\" % len(Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num train: 741770\n",
            "num test: 247257\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpWV2PJI_9J-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare data for Pyro\n",
        "X_train = torch.tensor(X_train[:2000,:]).float()\n",
        "Y_train = torch.tensor(Y_train[:2000,:]).float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "604hxdiu4s9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def categorical_model(X, obs=None):\n",
        "    input_dim = X.shape[1]\n",
        "    n_cat = obs.shape[1]\n",
        "\n",
        "    alpha = pyro.sample(\"alpha\", dist.Normal(torch.zeros(1, n_cat), 5.*torch.ones(1, n_cat)))\n",
        "    beta  = pyro.sample(\"beta\", dist.Normal(torch.zeros(input_dim, n_cat), 5.*torch.ones(input_dim, n_cat)))\n",
        "\n",
        "    with pyro.plate(\"data\"):     \n",
        "        y = pyro.sample(\"y\", dist.OneHotCategorical(logits=alpha + X.matmul(beta)), obs=obs)\n",
        "        \n",
        "    return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiHO0fjn4s9_",
        "colab_type": "code",
        "outputId": "5d88377e-ff5f-4523-bd4f-2ff055b23a93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "# Define guide function\n",
        "guide = AutoDiagonalNormal(categorical_model)\n",
        "\n",
        "# Reset parameter values\n",
        "pyro.clear_param_store()\n",
        "\n",
        "# Define the number of optimization steps\n",
        "n_steps = 6000\n",
        "\n",
        "# Setup the optimizer\n",
        "adam_params = {\"lr\": 0.005}\n",
        "optimizer = ClippedAdam(adam_params)\n",
        "\n",
        "# Setup the inference algorithm\n",
        "elbo = Trace_ELBO(num_particles=2)\n",
        "svi = SVI(categorical_model, guide, optimizer, loss=elbo)\n",
        "\n",
        "# Do gradient steps\n",
        "for step in range(n_steps):\n",
        "    elbo = svi.step(X_train, Y_train)\n",
        "    if step % 500 == 0:\n",
        "        print(\"[%d] ELBO: %.1f\" % (step, elbo))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0] ELBO: 27839.5\n",
            "[500] ELBO: 5041.9\n",
            "[1000] ELBO: 4310.7\n",
            "[1500] ELBO: 3995.4\n",
            "[2000] ELBO: 3820.1\n",
            "[2500] ELBO: 4008.2\n",
            "[3000] ELBO: 3731.1\n",
            "[3500] ELBO: 3724.6\n",
            "[4000] ELBO: 3805.8\n",
            "[4500] ELBO: 3694.3\n",
            "[5000] ELBO: 3711.1\n",
            "[5500] ELBO: 3719.7\n",
            "CPU times: user 2min 23s, sys: 746 ms, total: 2min 24s\n",
            "Wall time: 48.3 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfHBuTzm4s-C",
        "colab_type": "code",
        "outputId": "81500064-ada1-4c0c-e326-0b4f6e83f84c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "from pyro.infer import Predictive\n",
        "\n",
        "predictive = Predictive(categorical_model, guide=guide, num_samples=2000,\n",
        "                        return_sites=(\"beta\", \"alpha\"))\n",
        "\n",
        "samples = predictive(X_train, Y_train)\n",
        "\n",
        "beta_samples = samples[\"beta\"].detach().numpy()\n",
        "alpha_samples = samples[\"alpha\"].detach().numpy()\n",
        "print(beta_samples.shape)\n",
        "print(alpha_samples.shape)\n",
        "\n",
        "# extract expected values of the parameters\n",
        "alpha_hat = samples[\"alpha\"].mean(axis=0).detach().numpy()\n",
        "beta_hat = samples[\"beta\"].mean(axis=0).detach().numpy()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2000, 30])\n",
            "torch.Size([2000, 24])\n",
            "(2000, 30, 24)\n",
            "(2000, 1, 24)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYkOnyw54s-F",
        "colab_type": "code",
        "outputId": "95842cc6-84fc-4079-f4bd-079b61d89105",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "# make predictions for test set\n",
        "Y_hat = alpha_hat + np.dot(X_test, beta_hat)\n",
        "\n",
        "#rebuild matrix\n",
        "Y_hat_arg=np.argmax(Y_hat,axis=1)\n",
        "Y_hat_pred=np.zeros((Y_hat.shape[0],Y_hat.shape[1]))\n",
        "for i in range(Y_hat.shape[0]): \n",
        "    Y_hat_pred[i,Y_hat_arg[i]]=1\n",
        "\n",
        "\n",
        "\n",
        "# evaluate prediction accuracy\n",
        "print(\"Accuracy:\",accuracy_full_line(Y_hat_pred, Y_test))\n",
        "print(sum(Y_hat))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.39837901454761643\n",
            "[-3382883.17643492 -3391114.76990595  1550071.35298242 -3378992.47272835\n",
            "  -464999.96931671 -2292062.81367076   -62369.48236465  1426008.50245764\n",
            "   556399.81223756 -1527962.36649473 -1317189.31481692   139308.37132694\n",
            "   816606.31206314    34352.00267389 -2493925.51511105  -473444.93292315\n",
            " -1009020.29400576  1093942.23350399   213024.92676781    -6409.747628\n",
            " -1325946.11381667 -3269174.22713931   355433.33052275  2006425.73605118]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nILrr9CSFTIh",
        "colab_type": "text"
      },
      "source": [
        "#Third model: hierarchical model\n",
        "\n",
        "So now, we complexify a little bit the model. Our assumption that we can use the same parameters beta for all the observations is too strong, because it means that all individuals give the same importance to all the features and have the same biases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6btRU3jBoPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Need to change this later, and to take into account all the features\n",
        "X_cat = np.concatenate([pd.get_dummies(train_df[x]) for x in columns_cat], axis=1)\n",
        "#We don't need the codpers to make predictions based on the profile\n",
        "X_num = train_df[columns_num[:-1]]\n",
        "X = np.concatenate([X_cat, X_num], axis=1)\n",
        "# standardize input features\n",
        "X_mean = X.mean(axis=0)\n",
        "X_std = X.std(axis=0)\n",
        "X = (X - X_mean) / X_std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMfRhs2aS6qD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e4221a18-e8d2-450f-c036-abdf152cfe23"
      },
      "source": [
        "km = KMeans(n_clusters = len(y_variables))\n",
        "km.fit(X)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
              "       n_clusters=24, n_init=10, n_jobs=None, precompute_distances='auto',\n",
              "       random_state=None, tol=0.0001, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zTiaqajBq8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ind = km.labels_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb_C1lGTBvzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Train/test split\n",
        "train_perc = 0.75 # percentage of training data\n",
        "split_point = int(train_perc*len(Y))\n",
        "perm = np.random.permutation(len(Y))\n",
        "ix_train = perm[:split_point]\n",
        "ix_test = perm[split_point:]\n",
        "X_train = X[ix_train,:]\n",
        "X_test = X[ix_test,:]\n",
        "ind_train = ind[ix_train]\n",
        "ind_test = ind[ix_test]\n",
        "Y_train = Y[ix_train]\n",
        "Y_test = Y[ix_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5aE1qZcByoo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare data for Pyro\n",
        "X_train = torch.tensor(X_train[:2000,:]).float()\n",
        "Y_train = torch.tensor(Y_train[:2000,:]).float()\n",
        "ind_train = torch.tensor(ind_train[:2000]).long()\n",
        "n_ind = max(ind_train) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_hF37cWF5_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def hierarchical_model(X, ind, n_ind, obs=None):\n",
        "    input_dim = X.shape[1]\n",
        "    n_cat = 24\n",
        "\n",
        "    alpha_mu = pyro.sample(\"alpha_mu\", dist.Normal(torch.zeros(n_cat), 10.*torch.ones(n_cat))) # Prior for the bias mean\n",
        "    alpha_sigma = pyro.sample(\"alpha_sigma\",  dist.HalfCauchy(10.*torch.ones(n_cat))) # Prior for the bias standard deviation\n",
        "\n",
        "    beta  = pyro.sample(\"beta\", dist.Normal(torch.zeros(input_dim, n_cat), 10.*torch.ones(input_dim, n_cat))) # Priors for the regression coefficents\n",
        "    \n",
        "    with pyro.plate(\"ind\", n_ind):\n",
        "        alpha = pyro.sample(\"alpha\", dist.Normal(alpha_mu, alpha_sigma).to_event(1)) # Draw the individual parameter for each individual\n",
        "\n",
        "    with pyro.plate(\"data\", X.shape[0]):\n",
        "        logits = alpha[ind] + X.matmul(beta)\n",
        "        y = pyro.sample(\"y\", dist.OneHotCategorical(logits=logits), obs=obs) # If you use logits you don't need to do sigmoid\n",
        "        \n",
        "    return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a41XNE45F-IG",
        "colab_type": "code",
        "outputId": "1424ce23-7d9f-4525-f7a2-069b1995c7a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "# Define guide function\n",
        "guide = AutoDiagonalNormal(hierarchical_model)\n",
        "\n",
        "# Reset parameter values\n",
        "pyro.clear_param_store()\n",
        "\n",
        "# Define the number of optimization steps\n",
        "n_steps = 5000\n",
        "\n",
        "# Setup the optimizer\n",
        "adam_params = {\"lr\": 0.005}\n",
        "optimizer = ClippedAdam(adam_params)\n",
        "\n",
        "# Setup the inference algorithm\n",
        "elbo = Trace_ELBO(num_particles=2)\n",
        "svi = SVI(hierarchical_model, guide, optimizer, loss=elbo)\n",
        "\n",
        "# Do gradient steps\n",
        "for step in range(n_steps):\n",
        "    elbo = svi.step(X_train, ind_train, n_ind, Y_train)\n",
        "    if step % 500 == 0:\n",
        "        print(\"[%d] ELBO: %.1f\" % (step, elbo))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0] ELBO: 55228.3\n",
            "[500] ELBO: 11183.3\n",
            "[1000] ELBO: 4923.8\n",
            "[1500] ELBO: 4293.7\n",
            "[2000] ELBO: 4512.4\n",
            "[2500] ELBO: 4025.8\n",
            "[3000] ELBO: 4147.4\n",
            "[3500] ELBO: 4643.6\n",
            "[4000] ELBO: 3994.5\n",
            "[4500] ELBO: 4741.0\n",
            "CPU times: user 2min 48s, sys: 661 ms, total: 2min 49s\n",
            "Wall time: 56.7 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjW0VGmjGVAc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyro.infer import Predictive\n",
        "\n",
        "predictive = Predictive(hierarchical_model, guide=guide, num_samples=2000,\n",
        "                        return_sites=(\"beta\", \"alpha\", \"alpha_mu\", \"alpha_sigma\"))\n",
        "samples = predictive(X_train, ind_train, n_ind, Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnrLNV4kGcVP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# extract expected values of the parameters\n",
        "alpha_hat = samples[\"alpha\"].mean(axis=0).detach().numpy()\n",
        "beta_hat = samples[\"beta\"].mean(axis=0).detach().numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZ54KiHIGhQF",
        "colab_type": "code",
        "outputId": "e4eaced9-b123-47ce-9d1a-a66cf46e9041",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# make predictions for test set\n",
        "Y_hat = alpha_hat[ind_test,:] + np.dot(X_test, beta_hat)\n",
        "\n",
        "Y_hat_arg=np.argmax(Y_hat,axis=1)\n",
        "Y_hat_pred=np.zeros((Y_hat.shape[0],Y_hat.shape[1]))\n",
        "for i in range(Y_hat.shape[0]): \n",
        "    Y_hat_pred[i,Y_hat_arg[i]]=1\n",
        "\n",
        "# evaluate prediction accuracy\n",
        "print(\"Accuracy:\",accuracy_full_line(Y_hat_pred, Y_test))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.47823591608909866\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sjrl4nSKzyWB",
        "colab_type": "code",
        "outputId": "b69db3cb-cbd3-4506-9133-9ed9a4e69db4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# make predictions for test set with codprov\n",
        "Y_hat = alpha_hat[ind_test,:] + np.dot(X_test, beta_hat)\n",
        "\n",
        "Y_hat_arg=np.argmax(Y_hat,axis=1)\n",
        "Y_hat_pred=np.zeros((Y_hat.shape[0],Y_hat.shape[1]))\n",
        "for i in range(Y_hat.shape[0]): \n",
        "    Y_hat_pred[i,Y_hat_arg[i]]=1\n",
        "\n",
        "# evaluate prediction accuracy\n",
        "print(\"Accuracy:\",accuracy_full_line(Y_hat_pred, Y_test))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.47823591608909866\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kldpNOU9J6Wn",
        "colab_type": "text"
      },
      "source": [
        "#Fourth model: add the product trends\n",
        "\n",
        "The dataset contains information about the products previously bought by some customers. We can use this to observ which products are the most popular"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbPjCvNNDNee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "products = train_df[y_variables]\n",
        "\n",
        "popular_products_vector = np.zeros(products.shape[1])\n",
        "\n",
        "for i, (name, values) in enumerate(products.iteritems()):\n",
        "    for val in values:\n",
        "      popular_products_vector[i] += val\n",
        "\n",
        "popular_products_vector /= products.shape[0]\n",
        "\n",
        "#normalization\n",
        "popular_products_vector = (popular_products_vector-min(popular_products_vector)) / (max(popular_products_vector)-min(popular_products_vector))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1nIdWjlb6cP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Need to change this later, and to take into account all the features\n",
        "X_cat = np.concatenate([pd.get_dummies(train_df[x]) for x in columns_cat], axis=1)\n",
        "#We don't need the codpers to make predictions based on the profile\n",
        "X_num = train_df[columns_num[:-1]]\n",
        "X = np.concatenate([X_cat, X_num], axis=1)\n",
        "\n",
        "# standardize input features\n",
        "X_mean = X.mean(axis=0)\n",
        "X_std = X.std(axis=0)\n",
        "X = (X - X_mean) / X_std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqTTFbE4erZz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ind = km.labels_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzK0dY43et0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Train/test split\n",
        "train_perc = 0.75 # percentage of training data\n",
        "split_point = int(train_perc*len(Y))\n",
        "perm = np.random.permutation(len(Y))\n",
        "ix_train = perm[:split_point]\n",
        "ix_test = perm[split_point:]\n",
        "X_train = X[ix_train,:]\n",
        "X_test = X[ix_test,:]\n",
        "ind_train = ind[ix_train]\n",
        "ind_test = ind[ix_test]\n",
        "Y_train = Y[ix_train]\n",
        "Y_test = Y[ix_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IszQ9mynewEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare data for Pyro\n",
        "X_train = torch.tensor(X_train[:2000,:]).float()\n",
        "Y_train = torch.tensor(Y_train[:2000,:]).float()\n",
        "ind_train = torch.tensor(ind_train[:2000]).long()\n",
        "n_ind = max(ind_train) + 1\n",
        "popular_products_vector = torch.tensor(popular_products_vector).float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWHlsLn_e09C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def final_model(X, ind, n_ind, products, obs=None):\n",
        "    input_dim = X.shape[1]\n",
        "    n_cat = 24\n",
        "    n_products = products.shape[0]\n",
        "\n",
        "    alpha_mu = pyro.sample(\"alpha_mu\", dist.Normal(torch.zeros(n_cat), 10.*torch.ones(n_cat))) # Prior for the bias mean\n",
        "    alpha_sigma = pyro.sample(\"alpha_sigma\",  dist.HalfCauchy(10.*torch.ones(n_cat))) # Prior for the bias standard deviation\n",
        "\n",
        "    beta  = pyro.sample(\"beta\", dist.Normal(torch.zeros(input_dim, n_cat), 10.*torch.ones(input_dim, n_cat))) # Priors for the regression coefficents\n",
        "    beta_products = pyro.sample(\"beta_product\", dist.Normal(torch.zeros(n_products, n_cat), 10.*torch.ones(n_products, n_cat)))\n",
        "\n",
        "    with pyro.plate(\"ind\", n_ind):\n",
        "        alpha = pyro.sample(\"alpha\", dist.Normal(alpha_mu, alpha_sigma).to_event(1)) # Draw the individual parameter for each individual\n",
        "\n",
        "    with pyro.plate(\"data\", X.shape[0]):\n",
        "        logits = alpha[ind] + X.matmul(beta) + products.matmul(beta_products)\n",
        "        y = pyro.sample(\"y\", dist.OneHotCategorical(logits=logits), obs=obs) # If you use logits you don't need to do sigmoid\n",
        "        \n",
        "    return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JSoWu05v16m",
        "colab_type": "code",
        "outputId": "0461a2ae-755f-489d-e291-d2f648ed3626",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "%%time\n",
        "# Define guide function\n",
        "guide = AutoDiagonalNormal(final_model)\n",
        "\n",
        "# Reset parameter values\n",
        "pyro.clear_param_store()\n",
        "\n",
        "# Define the number of optimization steps\n",
        "n_steps = 5000\n",
        "\n",
        "# Setup the optimizer\n",
        "adam_params = {\"lr\": 0.005}\n",
        "optimizer = ClippedAdam(adam_params)\n",
        "\n",
        "# Setup the inference algorithm\n",
        "elbo = Trace_ELBO(num_particles=2)\n",
        "svi = SVI(final_model, guide, optimizer, loss=elbo)\n",
        "\n",
        "# Do gradient steps\n",
        "for step in range(n_steps):\n",
        "    elbo = svi.step(X_train, ind_train, n_ind, popular_products_vector, Y_train)\n",
        "    if step % 500 == 0:\n",
        "        print(\"[%d] ELBO: %.1f\" % (step, elbo))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0] ELBO: 58804.7\n",
            "[500] ELBO: 11068.2\n",
            "[1000] ELBO: 5602.8\n",
            "[1500] ELBO: 5327.4\n",
            "[2000] ELBO: 5682.8\n",
            "[2500] ELBO: 5874.1\n",
            "[3000] ELBO: 4781.2\n",
            "[3500] ELBO: 4890.7\n",
            "[4000] ELBO: 5086.4\n",
            "[4500] ELBO: 4569.3\n",
            "CPU times: user 3min 9s, sys: 685 ms, total: 3min 10s\n",
            "Wall time: 1min 4s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u2rVTBFTwEnz",
        "colab": {}
      },
      "source": [
        "from pyro.infer import Predictive\n",
        "\n",
        "predictive = Predictive(final_model, guide=guide, num_samples=2000,\n",
        "                        return_sites=(\"beta\", \"alpha\", \"alpha_mu\", \"alpha_sigma\", \"beta_product\"))\n",
        "samples = predictive(X_train, ind_train, n_ind, popular_products_vector, Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xx1Sek4ZwEn1",
        "colab": {}
      },
      "source": [
        "# extract expected values of the parameters\n",
        "alpha_hat = samples[\"alpha\"].mean(axis=0).detach().numpy()\n",
        "beta_hat = samples[\"beta\"].mean(axis=0).detach().numpy()\n",
        "beta_product_hat = samples[\"beta_product\"].mean(axis=0).detach().numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2f6bb563-a2ae-497f-cb48-84d38e2ff848",
        "id": "XtcXxtXiwEn4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# make predictions for test set\n",
        "Y_hat = alpha_hat[ind_test,:] + np.dot(X_test, beta_hat) + np.dot(popular_products_vector, beta_product_hat)\n",
        "\n",
        "Y_hat_arg=np.argmax(Y_hat,axis=1)\n",
        "Y_hat_pred=np.zeros((Y_hat.shape[0],Y_hat.shape[1]))\n",
        "for i in range(Y_hat.shape[0]): \n",
        "    Y_hat_pred[i,Y_hat_arg[i]]=1\n",
        "\n",
        "# evaluate prediction accuracy\n",
        "print(\"Accuracy:\",accuracy_full_line(Y_hat_pred, Y_test))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.47716791657039054\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}